**Deep Learning on FPGAs: Past, Present, and Future**

1.  Abstract

2.  Introduction

    1.  The Case for FPGAs

3.  Deep Learning

    1.  Multi-layer Perceptrons

    2.  Convolutional Neural Networks

4.  FPGAs

    1.  High-Level Abstraction Tools

    2.  OpenCL

    3.  Proposed Design Flow for Deep Learning Development

5.  A Review of CNNs on FPGAs

6.  Looking Forward

    1.  Popular Deep Learning Software Tools

    2.  Increasing Degrees of Freedom for Training

    3.  Low Power Compute Clusters

7.  Conclusion

8.  현재 연구

```{=html}
<!-- -->
```
1.  Abstract

-   Deep Learning

    -   방대한 양의 데이터를 통해 알고리즘이 아닌 스스로 배울 수 있게 함

        -   훈련할 수 있고,신뢰할 수 있는 양의 데이터가 필요

        -   GPU(그래픽 처리 장치) 클러스터를 범용 프로바이저(GPGPU)로
            사용

    -   FieldProgrammableGateArray(FPGA)

        -   구조가 유연하며, 와트당 높은 성능을 제공하는 경향

            -   대규모 서버 기반deployment 또는 자원 제한 embedded
                애플리케이션에 관심이 있는 애플리케이션 과학자들에게
                중요

    -   하드웨어 가속도 관점에서 심층 학습과 FPGA 리뷰

        -   FPGA가 심층 학습의 요구에 가장 잘 부응할 수 있는 방법에 대한
            논의 유도

2.  Introduction

-   심층 학습을 위한 현재의 하드웨어 가속 상태

    -   그래픽 처리 장치(GPU)의 클러스터를 범용 프로세서(GPGPU)로 사용

    -   GPGPU 프로그래밍을 위한 NVIDIA CUDA 플랫폼이 가장 우세

        -   주요 심층 학습 도구가 이 플랫폼을 활용하여 GPU 가속화에 접근

    -   OpenCL은 딥 러닝 커뮤니티에서 지원 측면에서 CUDA에 못 미침

        -   CUDA와 구별되는 두 가지 특징

            -   Loyalty-free

            -   GPU, GPP, Field Programmable Gate Array(FPGA), Digital
                Signal Processor(DSP) 지원

    1.  The Case for FPGAs

    -   딥 러닝에 중요한 서브루틴의 경우 GPU보다 와트당 나은 성능 제공

    -   FPGA 프로그래밍에는하드웨어 특정 지식이 필요

    -   다양한 설계 도구를 고려하는 연구자에게

        -   사용자 친화적인 소프트웨어 개발 도구

        -   모델 설계를 위한 유연하고 업그레이드 가능한 방법

        -   대형 모델의 교육 시간을 단축하기 위한 빠른 계산

    -   딥 러닝 연구자에게

        -   FPGA를 프로그래밍하기 쉽게 만드는 높은 추상화 설계 도구의
            추세

        -   맞춤형 아키텍처를 허용하는 재구성성

        -   실행 속도를 가속화할 수 있는 대규모의 병렬성

    -   애플리케이션 과학자에게

        -   유사한 공구 레벨 선호도가 존재하지만, 하드웨어 선택에 있어
            강조점은 전력 소비량 와트당 성능을 최대화하여 대규모 운영
            비용을 절감

    -   이 논문에서는 FPGA에 대한 심층 학습 현황과 이 두 기술을 연결하는
        데 도움이 되는 최신 개발 상황을 확인

        -   새로운 하드웨어 가속 플랫폼을 탐구하기 위해 딥러닝 커뮤니티
            내에 존재하는 기회를 파악, FPGA를 이상적인 선택으로 제시

        -   딥 러닝을 위한 FPGA 지원의 현재 상태를 개략적으로 설명하여
            잠재적인 한계를 식별

3.  Deep Learning

-   딥 러닝

    -   신경망 연구를 중심으로 2006년경 생겨남

    -   초기 성공은 라벨이 없는 데이터에서 학습하는Unsupervised Learning
        기술

        -   심층 신경망의 층을 \"사전 훈련\"(초기화)하기 위해 무감독
            학습이 사용

        -   일반적인 방법, Gradation Backpropagation으로 훈련하기에는
            너무 어렵다고 생각됨

        -   GPGPU 컴퓨팅의 도입과 2000년대 말과 현재 10년 동안 더 큰
            데이터셋의 가용성으로 인해, Supervised Learning에 초점

        -   연구와 산업 모두에서 대부분의 관심을 받은 신경망 아키텍처는
            두 가지 유형이다.

            -   MLP(Multi-Layer Perceptron)와 CNN(Convolutional Neural
                Network)

    -   하드웨어 가속기를 사용한 병렬화에 적합한 대부분의 심층 학습
        모델과 애플리케이션의 특성

        -   데이터 병렬

            -   픽셀 기반입력(영상 및 비디오)에 전체 또는 로컬 영역에
                동시에 적용

            -   수백 또는 수천 개를 처리

            -   Mini-Batch 하나 하나를 독립적으로 처리 가능

        -   모델 병렬

            -   하드웨어에 배포된 뒤, 병렬로 업데이트될 수 있는 중복
                처리 장치로 구성

            -   복수의 GPU를 사용하여 CNN을 가속화하는 최근 연구

                -   데이터 및 모델 기반 병렬의 균형을 맞추기 위한 전략을
                    사용

                -   아키텍처의 부분들이 각각 다름에도 불구하고 최적의
                    방법으로 병렬화

        -   파이프라인 병렬

            -   MLP 및 CNN과 같은 아키텍처에서 피드-포워드 특성은
                파이프라인 병렬(예: FPGA)을 이용하기에 적합한 하드웨어가
                이점 제공 가능

            -   GPP와 GPU는 여러 코어에 병렬 스레드를 실행하는 데 의존

            -   FPGA는 깊은 파이프라인이 되어 있고 본질적으로 멀티스레딩
                되어 있는 맞춤형 하드웨어 회로 제작 가능

    1.  Multi-layer Perceptrons

    -   단순 피드 포워드 딥 네트워크

        -   다중 레이어 퍼셉트론(MLP),심층 학습의 중추

            -   첫 번째 (입력) 계층과 마지막 (출력) 계층 사이의 숨겨진
                계층을 가진 계층,하나 이상의 스칼라 출력이 있어야 함

            -   훈련 중에 조정되는 매개변수로서 가중치(시냅스와
                유사함)사용

            -   유닛들의의 집합은 기존의 기계 학습에서의 특징에 대한
                전통적인 개념과 유사한 단어인Feature를 사용

            -   전체 네트워크가 선형 변환으로 붕괴되는 것을 방지하기
                위해, 각 장치는 입력에 Element-wise적인 비선형 연산을
                적용

                -   Rectifed Linear Unit(ReLU)을 주로 사용

            -   기본 MLP는 그림 1에 참고

![스크린샷이(가) 표시된 사진 자동 생성된
설명](media/image1.tiff){width="6.263888888888889in"
height="6.247916666666667in"}

2.  Convolutional Neural Networks

-   현재 가장 인기 있는 심층 학습 아키텍처

-   픽셀 기반의 시각 인식 작업에 유리

-   공간적 또는 시간적 연속성을 측정하는 데이터를 위해 설계

-   데이터의 공간 연속성

    -   위치(i, j)에 있는 픽셀이 이미지의 로컬 영역에 있는 인접 영역과
        유사한 강도 또는 색상 특성을 공유하는 이미지에서 발견 가능

-   CNN은 몇 가지 중요한 Layer 유형의 다양한 조합으로 구성

    -   MLP에 비해 Feature Map이라고 하는 단위의 2D 배열로 구성

    -   MLP의 Linear Featrue추출 작업과 유사한 Convolution Layer

    -   입력Feature Map의 작은 수용 필드에 로컬로 연결되고, 입력의 모든
        위치에서 공유되는 학습 가능한 필터(커널)에 의해 파라미터화

    -   CNN의 Feature 추출은 이러한 필터와 Convolution

    -   풀링 레이어는 FeatureMap의 로컬 영역에 Simple Reduction 연산(예:
        최대 또는 평균)을 적용

        -   형상 지도의 크기가 줄어들어 연산 및 매개변수 감소에는 유리

        -   Shift-Invariance도 소량 산출

    -   Feature Map의 Spatial/Temporal로 조직된 정보를
        Classification이나 Regression과 같은 의사결정으로 줄이기 위해
        하나 이상의 Fully-Connected Layer(MLP에서 사용되는 동일한
        계층)을 출력 계층에 적용

4.  FPGAs

-   가속을 위한 하드웨어 플랫폼을 평가할 때, 유연성과 성능의 절충을 고려

-   범용 프로세서(GPP)

    -   유연성과 사용 편의성을 제공하지만 상대적으로 비효율적성능

    -   이러한 플랫폼은 보다 쉽게 접근할 수 있고, 저렴하게 생산할 수
        있으며, 다양한 용도와 재사용에 적합

-   애플리케이션 특화 통합 회로(ASIC)

    -   유연성이 떨어지고 생산이 어렵고,비용이 높지만고성능을 제공

    -   특정한 용도에만 사용되며 생산하는데 비용이 많이 들고 시간이 많이
        소요

-   FPGA

    -   이 두 극단 사이에서 절충

    -   일반적인 종류의 프로그래머블 논리 장치(PLD)

        -   가장 단순한 의미에서 재구성 가능한 통합 회로

        -   GPP의 재구성 가능한 유연성과 함께 통합 회로의 장점을 제공

    -   플립 플롭(FF)과 룩업 테이블(LUT)을 사용하여 순차적 로직을 구현

    -   현대의 FPGA는 또한 풀 프로세서 코어, 통신 코어, 산술 코어, 블록
        RAM(Block RAM)과 같이 일반적으로 사용되는 기능을 위한 강화된
        구성요소를 포함

    -   현재의 FPGA 트렌드

        -   ARM 코프로세서와 FPGA가 일반적으로 동일한 Fabric에서
            발견되는 시스템온칩(SoC) 설계 접근방식

    -   현재 FPGA 시장

        -   Xilinx와 Altera가 장악,총 85%의 시장점유율을 차지

        -   FPGA는 Fixed Function Logic을 위해 ASIC와
            응용특정표준제품(ASSP)을대체

        -   FPGA 시장은 2016년까지 100억 달러에 이를 것으로 예상

-   심층 학습에서의 FPGA

    -   GPP

        -   GPP에 대한 소프트웨어 수준의 Execution은 필요할 때 가져올
            외부 메모리에 명령과 데이터를 저장하는 전통적인 Von Neuman
            아키텍처에 의존

        -   이것은 캐시의 모티브로써, 많은 비용이 드는 외부 메모리
            작업을 경감

        -   아키텍처의 병목현상은 프로세서 및 메모리 통신

            -   심층 학습에서 자주 요구되는 메모리 바인딩 기법에 대해
                GPP 성능을 저해

    -   FPGA

        -   프로그램 가능한 논리 셀은 Von Neuman 아키텍처에 의존하지
            않는 공통 논리 함수에서 발견되는 데이터 및 제어 경로를
            구현하는 데 사용 가능

        -   분산 온칩 메모리뿐만 아니라 feed forward 자연 깊은 학습
            방법에 자연스럽게 맞는 대규모의 파이프라인 병렬 방식을 이용
            가능

        -   현대의 FPGA는 부분적으로 동적 재구성을 지원

            -   다른 FPGA가 사용되는 중에 FPGA의 일부는 재프로그래밍될
                수 있음

                -   이는 FPGA에서 개별 계층을 재구성하는 동시에 다른
                    계층에서 진행 중인 계산을 중단하지 않음

                    -   대규모 심층 학습 모델에 영향을 미칠 수 있음

                -   단일 FPGA에 맞추기에는 너무 클 수 있는 모델을 수용할
                    수 있음

                -   중간 결과를 로컬 메모리에 보관하여 값비싼 글로벌
                    메모리 읽기 줄임

-   GPUvs. FPGA

    -   하드웨어의 설계를 가속화하는 것이 무엇을 의미하는지 다른 관점
        제공

        -   GPU와 기타 고정형 아키텍처를 통해 소프트웨어 실행 모델을
            따름

        -   독립 컴퓨팅 유닛에서 병렬로 작업을 실행하는 것을 중심으로
            구조화

    -   GPU에 대한 심층 학습 기법 개발의 목표

        -   알고리즘을 적응시켜, 병렬로 연산이 이루어지고, 데이터
            상호의존성이 확보되는 이 모델을 따르는 것

    -   FPGA 아키텍처는 애플리케이션에 적합

        -   FPGA를 위한 심층 학습 기법을 개발할 때, 고정된 계산 구조에
            대한 알고리즘의 적응에 대한 강조가 적기 때문에 알고리즘 수준
            최적화를 더 자유롭게 탐색 가능

        -   높은 수준의 소프트웨어 언어로 쉽게 구현할 수 없는 많은
            복잡한 낮은 수준의 하드웨어 제어 작업이 필요한 기법 사용
            가능

        -   유연성은 큰 컴파일(장소 및 경로) 시간의 비용이 발생

            -   설계 주기를 통해 신속하게 반복해야 하는 연구자들에게
                문제가 됨

        -   하드웨어 언어 습득의 문제

            -   FPGA에서 가장 인기 있는 언어:Verilog와 VHDL(하드웨어
                기술 언어, HDL)

                -   전통적인 소프트웨어 언어의 주요 차이점:HDL이
                    하드웨어를 단순하게 기술하고 있는 반면, C와 같은
                    소프트웨어 언어는 하드웨어 레벨 구현 세부사항을
                    이해할 필요 없음

                -   하드웨어를 효율적으로 기술하려면 디지털 설계와
                    회로에 대한 실무 지식이 필요

                -   로우 레벨 구현 결정 중 일부는 자동 도구에 맡길 수
                    있지만, 이는 항상 효율적인 설계로 귀결되는 것은 아님

                -   이러한 추세로 인해 FPGA 커뮤니티는 높은 수준의
                    추상화를 가진 설계 도구를 선호

    1.  High-Level Abstraction Tools

-   Xilinx와 Altera

    -   낮은 수준의 하드웨어 프로그래밍을 추상화하는 설계 도구

    -   HLS(High-level Synthesis) 툴은 높은 수준의 설계를 낮은 수준의
        레지스터-트랜스퍼 레벨(RTL) 또는 HDL 코드로 변환

    -   모델 기반 프레임워크, 고급 언어 기반 프레임워크, HDL 유사 언어,
        C 기반 프레임워크 및 병렬 컴퓨팅 프레임워크(예: CUDA/OpenCL)의
        다섯 가지 주요 범주로 분류

    -   이 논문에서는딥 러닝과 FPGA에 대해 다루기 때문에, 병렬 컴퓨팅
        프레임워크에 초점

    1.  OpenCL

-   OpenCL

    -   아키텍처의 알고리즘 가속화를 위한 개방형 소스, 표준화된
        프레임워크

    -   C 기반 언어(C99)

    -   OpenCL로 작성된 프로그램은 GPP, GPU, DSP, FPGA에서실행 가능

    -   CUDA와 유사점

        -   하드웨어에 대한 낮은 수준의 접근

        -   병렬 프로그래밍을 위한 표준 프레임워크를 제공

    -   CUDA와 주요 차이점

        -   소유권

            -   CUDA: NVIDIA가 만든 독점 프레임워크

            -   OpenCL:오픈소스, Loyalty free, 크로노스 그룹에 의해 유지

        -   OpenCL은 다양한 하드웨어 플랫폼 프로그래밍을 지원

            -   이러한 유연성은 모든 지원 플랫폼이 모든 OpenCL 기능을
                지원하는 것을 보장하지 않음

                -   FPGA의 경우, 현재 OpenCL 기능 중 일부만 지원

    -   두 프레임워크의 성능은 매우 유사

-   Altera와 Xilinx

    -   FPGA에 OpenCL SDK를 채택

        -   FPGA 설계와 함께 제공되는 고성능 및 저전력 편익을 이용 가능

        -   OpenCL을 채택도 비슷한 이유에서 채택됨

    1.  Proposed Design Flow for Deep Learning Development

-   주요 과제

    -   설계 컴파일 시간

        -   Altera와 Xilinx는 주로 OpenCL 커널을 위한 오프라인 컴파일을
            지원

        -   OpenCL 커널 컴파일 시간이 수십 분에서 몇 시간 정도인 반면
            GPP/GPU에 대한 일반 OpenCL 커널을 컴파일하는 것은 밀리초
            단위부터 초 단위까지 줄어듬

        -   심층 학습 도구는 설계 단계에서 동일한 사전 컴파일된 커널을
            재사용하는 경우가 많기 때문에 심층 학습에서도 똑같이
            적용되는 것은 아님

        -   CUDA가 지원하는 심층 학습 도구 또한 비슷한데, CUDA는
            Real-time 컴파일 접근법을 사용

        -   일반적으로 사용되는 심층 학습 커널을 일회성 컴파일하는 것은
            보통 이러한 커널을 설계하지 않고 단지 사용에만 관심이 있는
            응용 과학자들을 제한하는 합리적인 약속

        -   그림 2는 이미지 분류 모델의 전개를 위한 예시 흐름

![스크린샷이(가) 표시된 사진 자동 생성된
설명](media/image2.tiff){width="6.263888888888889in"
height="4.385416666666667in"}

-   커널 설계

    -   Altera와 Xilinx 모두 OpenCL 도구의 통합 커널 프로파일링, 디버깅
        및 최적화를 지원

    -   두 회사 모두 소프트웨어의 커널 시뮬레이션에 대해 지원

        -   의미 오류나 구문 오류와 같은 비하드웨어 문제를 디버깅할 때
            긴 컴파일 시간을 처리해야 하는 번거로움을 없앨 수 있음

5.  A Review of CNNs on FPGAs

-   현대의 FPGA

    -   밀도를 높이기 위해 더 작은 피쳐 크기를 계속 활용

    -   일반 FPGA 패브릭과 함께 강화된 연산 장치를 통합

    -   딥 네트워크를 단일 FPGA 시스템에 구현 가능

    -   FPGA 딥러닝 연구에서의 중요한 사건의 간략한 연대표는 그림 3에서
        볼 수 있음

![스크린샷이(가) 표시된 사진 자동 생성된
설명](media/image3.tiff){width="6.263888888888889in"
height="2.1145833333333335in"}

-   신경망의 첫 FPGA 구현

    -   1992년 콕스 외 연구진에게 첫 구현이 인정

    -   클루티어 외는 이러한 노력을 최초로 탐구한 사람 중 하나였지만,
        당시에는 FPGA 크기 제약으로 제한

        -   이 당시 FPGA는 오늘날의 FPGA에 존재하는
            Multiply-Accumulate(MAC) 단위를 포함하지 않았기 때문에, 매우
            느림

    -   가장 주목할 만한 것은 기능(트랜지스터) 크기가 감소함에 따라
        Motivated FPGA Fabric의 밀도가 크게 증가

    -   FPGA에 존재하는 경화된 연산 단위의 수가 증가

    -   CNN의 최첨단 FPGA 구현은 이러한 두 가지 설계 개선의 이점을 모두
        활용

        -   마이크로소프트의 한 팀이 FPGA에 CNN을 forward propagation
            하기 위한 최첨단 성과를 달성

-   오브차로프 외 ImageNet 1K 데이터 세트\[28\]에서 초당 134개의 이미지
    처리량을 보고

    -   Stratix V D5에서 25W로 작동

    -   다른 경쟁자의 처리량의 약 3배

    -   최고 수준의 FPGA를 사용함으로써 증가할 것으로 예상

-   Arria 10 GX1150에서 대략적으로 동일한 전력을 소비하면서 초당 약
    233개의 이미지출력

    -   235 W를 소비하면서 500-824 이미지/초를 달성하는 고성능 GPU
        구현(Caffe + CuDNN)

    -   FPGA를 데이터 센터 애플리케이션에 통합하는 실험 프로젝트인
        마이크로소프트(MS) 설계 FPGA 보드와 서버를 사용하여 달성

    -   이 프로젝트는 대규모 검색 엔진 성능을 2배 향상시켜 이러한 유형의
        FPGA 응용 프로그램에 대한 가능성을 보여줌

-   Virtex 7 485T에서 초당 46개의 영상 처리량을 달성

    -   이 분야의 주요 경쟁업체들을 능가하는 성과

    -   이러한 구현의 대부분은 일반적으로 오프칩 메모리 액세스를
        사용하는 구조적으로 유사한 설계를 포함

-   더 많은 연구가 필요하기 때문에, 특정한 최적의 아키텍처 결정을
    결정하기는 어려움

-   사전 훈련된 CNN은 알고리즘적으로 간단하고 계산적으로 효율적이기
    때문에 대부분의 FPGA 노력은 이러한 모델의 forward propagation을
    가속화하고 달성된 처리량을 보고하는 것을 포함

    -   이는 많은 양의 데이터를 가능한 한 빠르고 효율적으로 처리하기
        위해 미리 훈련된 네트워크를 사용하고자 하는 애플리케이션
        엔지니어에게 가장 중요

    -   그러나 이는 FPGA에 대한 역전파를 가속화하는 것도 포함

        -   FPGA에 대한 CNN 설계 고려사항의 한 측면만을 나타냄

        -   Paul 등은 2006년 Virtex E FPGA에서 학습 단계를 최초로 완전
            병렬화 함

6.  Looking Forward

-   확장성

    -   미래의 문제에대해서는 계속 성장하는 데이터 크기와 아키텍처를
        수용하도록 확장

    -   FPGA 기술은 하드웨어가 다중 FPGA 구성을 수용하기 위해 더 큰
        메모리, 더 작은 기능 크기, 상호 보완을 지향하기 때문에 이러한
        추세를 지원하기 위해 적응

    -   알테라의 인텔 인수는 IBM과 Xilinx의 파트너십과 함께 FPGA 환경의
        변화를 나타내며, 이는 가까운 미래에 소비자 및 데이터 센터
        애플리케이션에서 FPGA의 통합을 볼 수도 있음

    -   설계 도구는 보다 광범위한 사용자들을 끌어들이기 위해 더 높은
        수준의 추상화 및 소프트웨어와 같은 경험을 지향할 가능성이 있음

    1.  Popular Deep Learning Software Tools

    -   딥 러닝을 위한 가장 인기 있는 소프트웨어 패키지들

![스크린샷이(가) 표시된 사진 자동 생성된
설명](media/image4.tiff){width="6.263888888888889in"
height="1.6493055555555556in"}

-   아직 FPGA를 지원하는 소프트웨어 패키지는 명시적으로 없음

2.  Increasing Degrees of Freedom for Training

-   하이퍼 파라미터

    -   교육 반복 횟수, 학습 속도, 미니바치 크기, 숨겨진 단위 수, 레이어
        수 등은 모두 조정할 수 있는 하이퍼 파라미터의 예시

    -   이러한 값을 조정하는 행위는 가능한 모든 모델의 집합 중에서 특정
        문제에 가장 적합한 모델을 선택하는 것

    -   전통적으로 하이퍼 파라미터는 경험에 의해 설정되거나 그리드
        검색에 의해 체계적으로 설정되거나 더 효과적으로 무작위 검색으로
        설정

    -   베이시안 최적화가 가장 인기가좋음

    -   FPGA는 런타임에 하이퍼 파라미터를 조절 가능하여 최적화에 더 적합

    1.  Low Power Compute Clusters

    -   확장 능력

        -   심층 학습 기법은 멀티 노드 컴퓨팅 인프라에 걸쳐 확장

            -   높은 수준의 병렬 컴퓨팅 성능과 노드 간 빠른 데이터
                전송을 허용하기 위해 Infiniband Interconnect와 MPI가
                있는 GPU 클러스터를 사용하는 것을 포함

        -   이러한 대규모 애플리케이션의 워크로드가 점점 이질화

            -   FPGA의 사용은 우수한 대안으로 판명

        -   FPGA의 프로그래밍 가능성은 애플리케이션과 워크로드에 기반한
            재구성을 허용

        -   매력적인 성능/와트를 제공

7.  Conclusion

-   딥 러닝의 하드웨어 요구를 해결할 때, FPGA는 GPU와 GPP에 대한
    매력적인 대안을 제공

-   파이프라인 병렬 방식을 활용하고 효율적인 전력 소비율을 달성할 수
    있는 능력은FPGA의 고유한장점

-   설계 도구는 FPGA를 대중적인 심층 학습 프레임워크로 통합할 수 있을
    정도로 성숙

-   FPGA는 심층학습의 추세를 효과적으로 수용 가능

8.  현재 연구

-   서울대학교 매니코어 프로그래밍 연구단(<http://aces.snu.ac.kr/>)에서
    FPGA딥러닝 클러스터와 소프트웨어 스택을 개발,연구하는 논문을 발표
    준비 중이며 현재 컴파일러 제작까지 완료
